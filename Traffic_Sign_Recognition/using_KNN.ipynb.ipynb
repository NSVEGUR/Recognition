{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic Sign Recognition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets get a overview of steps performing in traffic sign recognition.\n",
    "- Data preprocessing using `open cv`.\n",
    "- Dimensionality reduction using `PCA`.\n",
    "- Training the model on [GTRSB](https://www.kaggle.com/datasets/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign) traffic signs dataset and testing.\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from time import time\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "image_vector_size = 30\n",
    "classes = 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "Here we read some of the training images in `GTRSB` dataset and use them both for our train and test using opencv library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess():\n",
    "\tdef __init__(self, path):\n",
    "\t\t\"\"\"\n",
    "\t\tCalled when class is created with the variables of data\n",
    "\t\t\"\"\"\n",
    "\t\tself.path = path\n",
    "\n",
    "\tdef get_data(self):\n",
    "\t\t\timages = []\n",
    "\t\t\tlabels = []\n",
    "\t\t\tdir = os.listdir(self.path)\n",
    "\t\t\tfor cl in range(classes):\n",
    "\t\t\t\tlabel = str(cl)\n",
    "\t\t\t\timg_dir_path = self.path + '/' + label\n",
    "\t\t\t\timg_dir = os.listdir(img_dir_path)\n",
    "\t\t\t\tfor img in img_dir:\n",
    "\t\t\t\t\tif not img.startswith(\".\"):\n",
    "\t\t\t\t\t\timg_path = img_dir_path + '/' + img\n",
    "\t\t\t\t\t\timage = cv2.imread(img_path)\n",
    "\t\t\t\t\t\timage = cv2.resize(image, (image_vector_size, image_vector_size), interpolation = cv2.INTER_AREA)\n",
    "\t\t\t\t\t\timage = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\t\t\t\t\t\timages.append(np.array(image))\n",
    "\t\t\t\t\t\tlabels.append(cl)\n",
    "\t\t\treturn (images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Reading Images ......\n",
      "Images Read in  4.750s\n"
     ]
    }
   ],
   "source": [
    "training_path = \"Data/Train\"\n",
    "\n",
    "t0 = time()\n",
    "print(\"Started Reading Images ......\")\n",
    "preprocessor = Preprocess(training_path)\n",
    "images_train, labels_train = preprocessor.get_data()\n",
    "print(\"Images Read in % 0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(images_train, labels_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality reduction\n",
    "\n",
    "Here we perform dimensionality reduction of our feature vectors using PCA for both training and testing data to use KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in  2.637s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "n_components = 5\n",
    "\n",
    "n_samples_train = np.array(X_train).shape[0]\n",
    "n_samples_test = np.array(X_test).shape[0]\n",
    "\n",
    "X_train = np.array(X_train).reshape(n_samples_train, image_vector_size*image_vector_size)\n",
    "X_test = np.array(X_test).reshape(n_samples_test, image_vector_size*image_vector_size)\n",
    "\n",
    "\n",
    "t0 = time()\n",
    "pca = PCA(n_components = n_components, svd_solver ='randomized',\n",
    "          whiten = True).fit(X_train)\n",
    "\n",
    "X_train_reduced = pca.transform(X_train)\n",
    "X_test_reduced = pca.transform(X_test)\n",
    "\n",
    "print(\"done in % 0.3fs\" % (time() - t0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "Lets predict our test data using simpler and lazier model 1-NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is: 0.9284253578732107\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=1)\n",
    "clf.fit(X_train, y_train)\n",
    "score = clf.score(X_test, y_test)\n",
    "print(f\"Accuracy score is: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6863e040e8981097dbf29d10dc72ab85d80010d98b5512de1073715d1caccbff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
